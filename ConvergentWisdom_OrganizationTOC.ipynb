{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYzHFD5ng6mh9LP+VRzfVr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justinjunge/Convergent-Wisdom-Project/blob/main/ConvergentWisdom_OrganizationTOC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convergent Wisdom\n",
        "## Annotated Table of Contents\n",
        "\n",
        "Context: The Convergent Wisdom project is an effort to gain insight on sacred texts from a variety of widely practiced faith traditions by applying modern tools from computer science, natural language processing, and data science.  It is a not-for-profit project and collaboration, and contributors are welcome!\n",
        "\n",
        "Summary: This document contains a map of the current state of the project  along with highlighted future directions in **bold** (and includes concise descriptions of each section and file).  \n",
        "\n",
        "###1. Frequency Analyses  \n",
        "Overview: Counting the occurence of specific words and groups of words in a text.  One way frequency analyses can be visualized is using Word Clouds.  \n",
        "file list:  \n",
        "[Sample Word Cloud](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/Sample_Word_Cloud_Analysis.ipynb)\n",
        "\n",
        "[Sacred Text Word Cloud](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/Holy_Texts_Word_Cloud_Analysis.ipynb)  \n",
        "\n",
        "\n",
        "####1a. Frequency Sums & Temporal Distributions  \n",
        "Overview: Counting and then displaying/visualizing the number of occurences of a specific word in a text can be accomplished multiple ways, including their distribution over time or the progression of a text (e.g. per chapter).    \n",
        "file list: [sample files are below under Sentiment Analyses]  \n",
        "\n",
        "\n",
        "####1b. Sentiment Analyses  \n",
        "Overview:  When the groups of words analyzed by frequency are about emotion/feeling/valence, this is a form of Sentiment Analysis.  A common method of sentiment analysis is to create lists of words for each emotion (e.g. a list of positive words, a list of negative words) and then count how frequently words from each list appear (overall, or in each subsection of a text).    \n",
        "file list:  \n",
        "[Sample Sentiment Analysis](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/Sample_Sentiment_Analysis.ipynb)\n",
        "\n",
        "[Sacred Texts Sentiment Analysis](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/Holy_Texts_Sentiment_Analysis.ipynb)  \n",
        "\n",
        "\n",
        "\n",
        "###2. Semantic Analyses\n",
        "Overview:  Words, sentences, paragraphs, chapters, books, collections of books have meanings.  Semantic analyses use a model of how units of meaning relate to other units of meaning.  One method to produce a model is called vector embedding.  You can learn more about [Vector Embeddings here.](https://cloud.google.com/blog/topics/developers-practitioners/meet-ais-multitool-vector-embeddings)\n",
        "\n",
        "file list:  \n",
        "[Semantic Analyses](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/June24_Sacred_Texts_Heatmap_Analysis.ipynb)\n",
        "\n",
        "\n",
        "####2a. Vector Embeddings\n",
        "The following vector embeddings were created using the model [all-mpnet-base-v2] from [HuggingFace](https://huggingface.co/sentence-transformers/all-mpnet-base-v2):  \n",
        "[Bible vector embedded by chapter](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/Vector_Embeddings/Bible_chapter.pt)  \n",
        "[Gita vector embedded by verse](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/Vector_Embeddings/Gita5_Embedding.pt)  \n",
        "[Qu'ran vector embedded by chapter](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/Vector_Embeddings/Quran_chapter_Embeddings.pt)  \n",
        "\n",
        "The vector embeddings were made from these files:  \n",
        "[Qu'ran](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/CSV_files/Quran.csv)  \n",
        "[Bible](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/CSV_files/ChristianBible.csv)  \n",
        "[Gita CSV](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/CSV_files/Gita.csv)  \n",
        "Note that the Gita CSV used for Vector Embedding was edited slightly from the public domain version linked below, for formatting compatibility.\n",
        "\n",
        "\n",
        "## Additional References\n",
        "[links to articles and various resources we consulted and found helpful while developing this project]\n",
        "\n",
        "\n",
        "\n",
        "[Public Domain Gita CSV](https://www.kaggle.com/datasets/madhurpant/bhagavad-gita-verses-dataset)\n",
        "\n",
        "[Public Domain Qu'ran as CSV](https://www.kaggle.com/datasets/zusmani/the-holy-quran?select=English.csv)\n",
        "\n",
        "[Publich Domain Bible as CSV](https://github.com/justinjunge/Convergent-Wisdom-Project/blob/main/CSV_files/ChristianBible.csv)"
      ],
      "metadata": {
        "id": "R7LB3QYiBoW8"
      }
    }
  ]
}